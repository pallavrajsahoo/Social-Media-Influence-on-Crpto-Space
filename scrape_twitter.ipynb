{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping tweets from Twitter using Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following are the credentials to access Tweepy\n",
    "\n",
    "access_token = '486676958-t4zma8lIm6PqOZXncwwLIQXfiYKpCJTxvbO9SQ33'\n",
    "access_token_secret = 'rcyisbLub6YajCqFXaPSAh41Lc28tTmNgnAPxzqr2Ye1m'\n",
    "consumer_key = '8nbgq62bD0if9bqJgxtViQbWg'\n",
    "consumer_secret = 'YNBt5JEXU1OeALrzMh8U7dRM87gtBLJAcBiyTmGNubo92AZXe4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the above twitter credentials to tweepy via its OAuthHandler\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Initialization\n",
    "\n",
    "tweets = []\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print (\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t| you can comment out data you don't need\n",
    "    outtweets = [[tweet.id_str.encode(\"utf-8\"), \n",
    "                tweet.created_at, \n",
    "                tweet.favorite_count, \n",
    "                tweet.retweet_count, \n",
    "                tweet.retweeted, \n",
    "                tweet.source.encode(\"utf-8\"), \n",
    "                tweet.text.encode(),] for tweet in alltweets]\n",
    "\n",
    "    #write the csv\n",
    "    with open('./CEOs/%s_tweets.csv' % screen_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\n",
    "                \"created_at\",\n",
    "                \"favorites\", \n",
    "                \"retweets\",\n",
    "                \"retweeted\", \n",
    "                \"source\", \n",
    "                \"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "    \n",
    "    pass\n",
    "\n",
    "# celebrities=['mcuban','elonmusk','mrbeast', 'RussellOkung', 'PeterSchiff']\n",
    "# angel_investors=['fredwilson','WhalePanda','DiaryofaMadeMan','naval','kevinrose', '100trillionUSD']  \n",
    "# traders=['NicTrades','Sicarious','ActualAdviceBTC','ThinkingUSD','cointradernik','CRYPTOBANger','PeterMC', 'woonomic']\n",
    "\n",
    "ceos=['Satoshilite', 'justinsuntron',  'officialmcafee', 'arrington', 'cdixon', 'stoolpresidente' , 'APompliano', 'CryptoCred', 'rogerkver' ]\n",
    "for i in ceos:\n",
    "    get_all_tweets(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
